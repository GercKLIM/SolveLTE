{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.0\n",
      "Доступные устройства GPU:\n",
      "PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')\n"
     ]
    }
   ],
   "source": [
    "# Проверка работоспособности системы\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from PIL import Image\n",
    "print(tf.__version__)\n",
    "\n",
    "# Проверка подключения графического процессора\n",
    "print(\"Доступные устройства GPU:\")\n",
    "for device in tf.config.experimental.list_physical_devices('CPU'):\n",
    "    print(device)\n",
    "\n",
    "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание датасета для обучения\n",
    "\n",
    "# Функции загрузки и предобработки к каждому элементу датасета\n",
    "def load_and_preprocess_train_image(image_path, label):\n",
    "        img = tf.io.read_file(image_path)\n",
    "        img = tf.image.decode_png(img, channels=1)  # Черно-белые изображения\n",
    "        img = tf.image.resize(img, [128, 128])\n",
    "        img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "        return img, label\n",
    "\n",
    "# Функция, которая создает датасет из папки с изображениями\n",
    "def import_train_data(image_dir):\n",
    "    # Получение списка файлов с изображениями\n",
    "    image_files = []\n",
    "    for papka in os.listdir(image_dir):\n",
    "        papka_dir = image_dir + '/' + papka\n",
    "        for file in os.listdir(papka_dir):\n",
    "            if file.endswith('.png'):\n",
    "                image_files.append(os.path.join(papka_dir, file))\n",
    "\n",
    "   \n",
    "    print(\"Количество изображений:\",len(image_files))\n",
    "   \n",
    "    # Создание списка меток \n",
    "    labels = []\n",
    "    dict_labels = dict()\n",
    "    for i in range(0, len(image_files)):\n",
    "         # Создание индекса графика\n",
    "        label = tuple(((image_files[i].split('.png')[0]).split(\"\\\\\")[1]).split('_'))\n",
    "        labels.append(i)\n",
    "        dict_labels[label] = i\n",
    "\n",
    "    print(dict_labels)\n",
    "    print(\"Количество меток:\",len(set(labels)))\n",
    "    print(\"Распределение меток:\",labels)\n",
    "\n",
    "    # Создание датасета с использованием tf.data.Dataset.from_tensor_slices\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_files, labels))\n",
    "    # Применение функции загрузки и предобработки к каждому элементу датасета\n",
    "    dataset = dataset.map(load_and_preprocess_train_image)\n",
    "    \n",
    "    return dataset, dict_labels, len(dict_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество изображений: 45\n",
      "{('test1', '0'): 0, ('test1', '1'): 1, ('test1', '10'): 2, ('test1', '2'): 3, ('test1', '3'): 4, ('test1', '4'): 5, ('test1', '5'): 6, ('test1', '6'): 7, ('test1', '7'): 8, ('test1', '8'): 9, ('test1', '9'): 10, ('test2', '0'): 11, ('test2', '1'): 12, ('test2', '10'): 13, ('test2', '2'): 14, ('test2', '3'): 15, ('test2', '4'): 16, ('test2', '5'): 17, ('test2', '6'): 18, ('test2', '7'): 19, ('test2', '8'): 20, ('test2', '9'): 21, ('test3', '0'): 22, ('test4', '0'): 23, ('test4', '1'): 24, ('test4', '10'): 25, ('test4', '2'): 26, ('test4', '3'): 27, ('test4', '4'): 28, ('test4', '5'): 29, ('test4', '6'): 30, ('test4', '7'): 31, ('test4', '8'): 32, ('test4', '9'): 33, ('test5', '0'): 34, ('test5', '1'): 35, ('test5', '10'): 36, ('test5', '2'): 37, ('test5', '3'): 38, ('test5', '4'): 39, ('test5', '5'): 40, ('test5', '6'): 41, ('test5', '7'): 42, ('test5', '8'): 43, ('test5', '9'): 44}\n",
      "Количество меток: 45\n",
      "Распределение меток: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44]\n",
      "Кодификатор: {('test1', '0'): 0, ('test1', '1'): 1, ('test1', '10'): 2, ('test1', '2'): 3, ('test1', '3'): 4, ('test1', '4'): 5, ('test1', '5'): 6, ('test1', '6'): 7, ('test1', '7'): 8, ('test1', '8'): 9, ('test1', '9'): 10, ('test2', '0'): 11, ('test2', '1'): 12, ('test2', '10'): 13, ('test2', '2'): 14, ('test2', '3'): 15, ('test2', '4'): 16, ('test2', '5'): 17, ('test2', '6'): 18, ('test2', '7'): 19, ('test2', '8'): 20, ('test2', '9'): 21, ('test3', '0'): 22, ('test4', '0'): 23, ('test4', '1'): 24, ('test4', '10'): 25, ('test4', '2'): 26, ('test4', '3'): 27, ('test4', '4'): 28, ('test4', '5'): 29, ('test4', '6'): 30, ('test4', '7'): 31, ('test4', '8'): 32, ('test4', '9'): 33, ('test5', '0'): 34, ('test5', '1'): 35, ('test5', '10'): 36, ('test5', '2'): 37, ('test5', '3'): 38, ('test5', '4'): 39, ('test5', '5'): 40, ('test5', '6'): 41, ('test5', '7'): 42, ('test5', '8'): 43, ('test5', '9'): 44}\n",
      "Длина кодификатора: 45\n",
      "Количество классов:  45\n"
     ]
    }
   ],
   "source": [
    "# Путь к папке с изображениями для обучения\n",
    "train_image_dir = 'dataset_№1/train/'\n",
    "\n",
    "\n",
    "train_dataset, train_kodificator, output_classes = import_train_data(train_image_dir)\n",
    "\n",
    "batch_size = 1  # Количество изображений подаваемых нейросети за одну итерацию обучения\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "print(\"Кодификатор:\", train_kodificator)\n",
    "print(\"Длина кодификатора:\", len(train_kodificator))\n",
    "print(\"Количество классов: \", output_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_16 (Conv2D)          (None, 125, 125, 32)      544       \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPooli  (None, 31, 31, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 30, 30, 64)        8256      \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPooli  (None, 15, 15, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 14400)             0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 150)               2160150   \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 45)                6795      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2175745 (8.30 MB)\n",
      "Trainable params: 2175745 (8.30 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Создание модели\n",
    "model = Sequential()\n",
    "\n",
    "# Первый сверточный слой\n",
    "model.add(Conv2D(32, (4, 4), activation='relu', input_shape=(128, 128, 1)))\n",
    "\n",
    "# Пулинг для уменьшения размера\n",
    "model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "\n",
    "# Второй сверточный слой\n",
    "model.add(Conv2D(64, (2, 2), activation='relu'))\n",
    "\n",
    "# Пулинг для уменьшения размера\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Спец. слой, который переводит матрицу в вектор\n",
    "model.add(Flatten())\n",
    "\n",
    "# Полносвязный слой\n",
    "model.add(Dense(150, activation='relu'))\n",
    "\n",
    "# Выходной слой с нейронами (по одному для каждого класса) и softmax активацией\n",
    "model.add(Dense(output_classes, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 2s 52ms/step - loss: 0.0600 - accuracy: 0.9778 - val_loss: 0.0011 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=1, validation_data=train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Точность нейросети: 100.0\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(train_dataset)\n",
    "print ('Точность нейросети:', test_accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step\n",
      "Predicted class: 34\n"
     ]
    }
   ],
   "source": [
    "def load_and_preprocess_image(image_path):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_png(img, channels=1)  # Черно-белые изображения\n",
    "    img = tf.image.resize(img, [128, 128])\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img = tf.expand_dims(img, axis=0)  # Создание батча из одного изображения\n",
    "    return img\n",
    "\n",
    "# Пример пути к новому изображению\n",
    "img_path = 'dataset_№1/train/test5/test5_0.png'\n",
    "img = load_and_preprocess_image(img_path)\n",
    "\n",
    "\n",
    "# Получение предсказания\n",
    "predictions = model.predict(img)\n",
    "\n",
    "# Определение класса с наибольшей вероятностью\n",
    "predicted_class = tf.argmax(predictions, axis=1).numpy()[0]\n",
    "print('Predicted class:', predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, Loss: -0.027414830401539803\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9456\\4266535316.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mgenerate_image_for_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m     \u001b[1;31m# Инициализация случайного шума\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0minput_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9456\\4266535316.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(model, label, input_shape, steps, learning_rate)\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m# Нормализация изображения для предотвращения чрезмерных значений\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\gerce\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1062\u001b[0m               output_gradients))\n\u001b[0;32m   1063\u001b[0m       output_gradients = [None if x is None else ops.convert_to_tensor(x)\n\u001b[0;32m   1064\u001b[0m                           for x in output_gradients]\n\u001b[0;32m   1065\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1066\u001b[1;33m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[0;32m   1067\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1068\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1069\u001b[0m         \u001b[0mflat_sources\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\gerce\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     63\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     raise ValueError(\n\u001b[0;32m     65\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[0;32m     68\u001b[0m       \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m       \u001b[0msources\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\gerce\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[0mgradient_name_scope\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"gradient_tape/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    149\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\gerce\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\nn_grad.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m    412\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRegisterGradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Relu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_ReluGrad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOperation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 414\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgen_nn_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\gerce\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(gradients, features, name)\u001b[0m\n\u001b[0;32m  11786\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  11787\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  11788\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  11789\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 11790\u001b[1;33m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m  11791\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  11792\u001b[0m       return relu_grad_eager_fallback(\n\u001b[0;32m  11793\u001b[0m           gradients, features, name=name, ctx=_ctx)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ГЕНЕРАЦИЯ ИЗОБРАЖЕНИЯ ПО МЕТКЕ\n",
    "\n",
    "def generate_image_for_label(model, label, input_shape=(128, 128, 1), steps=10000, learning_rate=1.0):\n",
    "    # Инициализация случайного шума\n",
    "    input_img = tf.Variable(tf.random.uniform(input_shape))\n",
    "    \n",
    "    # Оптимизатор\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    for step in range(steps):\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(input_img)\n",
    "            predictions = model(tf.expand_dims(input_img, axis=0))\n",
    "            loss = -tf.reduce_mean(predictions[:, label])\n",
    "        \n",
    "        grads = tape.gradient(loss, input_img)\n",
    "        optimizer.apply_gradients([(grads, input_img)])\n",
    "        \n",
    "        # Нормализация изображения для предотвращения чрезмерных значений\n",
    "        input_img.assign(tf.clip_by_value(input_img, 0.0, 1.0))\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            print(f'Step {step}, Loss: {loss.numpy()}')\n",
    "    \n",
    "    return input_img.numpy()\n",
    "\n",
    "# Пример метки\n",
    "label = 0  # Замените на вашу метку\n",
    "\n",
    "# Генерация изображения\n",
    "generated_img = generate_image_for_label(model, label)\n",
    "\n",
    "# Визуализация изображения\n",
    "plt.imshow(generated_img.squeeze(), cmap='gray')\n",
    "plt.title(f'Generated Image for Label {label}')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gerce\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "#model.save(\"МОДЕЛИ\\model_dataset_1.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
